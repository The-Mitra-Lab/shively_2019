"""
This module is a toolbox to analyze a significant hits file generated by find_sig_promoters.py

Written by RDM 4/13/2016
Modified by RDM on 5/5/17 to include a flag in add_pwm_info() to remove overlaps or not
Modified by RDM on 8/15/17 to anchor TF name search in get_pssm

"""

from Bio import SeqIO
from Bio import Seq
from Bio.SeqRecord import SeqRecord
from Bio.SeqFeature import SeqFeature,FeatureLocation
from Bio.Alphabet import IUPAC
import argparse
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
import re
import itertools
from sklearn import metrics

class pssm:
	#class for handling position specific weight matrices.  
	#The actual pssm is in object.pssm

	def __init__(self,dict_of_list_of_log_odds,recommended_threshold = 0.0):
		self.pssm = dict_of_list_of_log_odds
		self.recommended_threshold = recommended_threshold
		if not sorted(self.pssm.keys())==['A','C','G','T']:
			raise ValueError("PSSM has wrong alphabet: %s - Use only with A C G T")
		self._letters = ['A','C','G','T']
		self.length = len(self.pssm['A'])
			 
	def __getitem__(self,letter):
		return self.pssm[letter]
	def calculate(self,sequence):
		"""Returns the PWM score for all positions"""
		"""Returns the PWM score for a given sequence for all positions. 
			Notes: 
			 - the sequence can only be a DNA sequence
			 - the search is performed only on one strand 
			 - if the sequence and the motif have the same length, a single number is returned 
			 - otherwise, the result is a one-dimensional list or numpy array     """ 
		
		sequence = str(sequence)
		m = self.length
		n = len(sequence)
		scores = [] 
		sequence = sequence.upper()
		for i in range(n-m+1):
			score = 0.0
			for position in range(m):
				letter = sequence[i+position]
				try:
					score += self.pssm[letter][position]
				except KeyError:
					score = _nan
					break
			scores.append(score)
		if len(scores)==1:
			return scores[0]
		else:
			return scores 

	def max(self):
		score = 0.0 
		letters = self._letters 
		for position in range(0, self.length): 
			score += max(self.pssm[letter][position] for letter in letters) 
		return score 

	def min(self):
		"""Minimal possible score for this motif. 
		 returns the score computed for the anticonsensus sequence.
		 """ 
		score = 0.0 
		letters = self._letters 
		for position in range(0, self.length): 
			score += min(self.pssm[letter][position] for letter in letters) 
		return score 
	
	def search(self, sequence, threshold=0.0, both_strands=True): 
		"""Find hits with PWM score above given threshold.
		A generator function, returning found hits in the given sequence 
		with the pwm score higher than the threshold."""

		"""modified 5/6/17 by RDM to return orientation and to fix 
		a bug with positions"""		
		sequence = sequence.upper() 
		n = len(sequence) 
		m = self.length 
		if both_strands: 
			rc = self.reverse_complement() 
		for position in range(0, n-m+1): 
			s = sequence[position:position+m] 
			score = self.calculate(s) 
			if score > threshold: 
				orientation = 1
				yield (position+1,position+self.length,score,orientation) #1 indexed
			if both_strands: 
				score = rc.calculate(s)
				orientation = -1 
				if score > threshold: 
					yield (position+self.length,position+1,score,orientation) 

	def reverse_complement(self): 
		values = {} 
		values["A"] = self.pssm["T"][::-1] 
		values["T"] = self.pssm["A"][::-1] 
		values["G"] = self.pssm["C"][::-1] 
		values["C"] = self.pssm["G"][::-1]  
		return self.__class__(values,self.recommended_threshold) 

def read_in_pssm_file(filename):
	log_odds_dict = {}
	with open(filename) as f:
		for line in f:
			line_list = line.split(' |')
			base_name = line_list[0]
			lo_list = [float(x) for x in line_list[1].split()]
			log_odds_dict[base_name] = lo_list
	return pssm(log_odds_dict)

def get_pssm(tf_name,directory = '/scratch/ref/rmlab/calling_card_ref/yeast/recommended/PWM/'):
	file_list = os.listdir(directory)
	pattern = "\."+tf_name  #added requirement that name starts with TF so I can make symmeterized 
	#matrices 8/15/17
	for file_name in file_list:
		if re.search(pattern,file_name,re.I):
			'''added one line to avoid ._ for file name'''
			if file_name[0]!=".":
				return read_in_pssm_file(directory+file_name)

def add_seq_to_frame(sighits_frame,yeast_genomic_sequence_file='/scratch/ref/rmlab/calling_card_ref/yeast/S288C_reference_sequence_R61-1-1_20080605.fsa',bases_into_gene=150):
	"""This function takes a significant hits files as input and returns a frame with the significant hits
	file as a frame plus the sequence of the intergenic region as an added column.  The sequence is a 
	SeqRecord object"""
	
	#open significant hits file and get top (or bottom) r entries.  
	

	#load the yeast genome into memory
	yeast_genome = {}
	count = 1
	for seq_record in SeqIO.parse(yeast_genomic_sequence_file,"fasta"):
		yeast_genome[count] = seq_record
		yeast_genome[count].alphabet = IUPAC.unambiguous_dna
		count = count + 1

	seq_frame = pd.DataFrame(index = sighits_frame.index,columns = ['Sequence'])

	#loop through the intergenic region names and put the corresponding sequences in a list of sequence records
	#name = name + chormosome and start and end.  Sequence = grabbed sequence

	for idx,row in sighits_frame.iterrows():
		ig_sequence = yeast_genome[int(sighits_frame.ix[idx,'Chr'])].seq[int(sighits_frame.ix[idx,'Start'])-1-bases_into_gene:int(sighits_frame.ix[idx,'End'])+bases_into_gene]
		ig_sequence.alphabet = IUPAC.unambiguous_dna
		seq_frame.ix[idx]["Sequence"] = ig_sequence
	sighits_frame = sighits_frame.join(seq_frame)
	return sighits_frame

def make_comparison_frame(file1,file2,name1 = 'TF1',name2 = 'TF2',poisson=True,bs = True):
	frame1 = pd.read_csv(file1, delimiter = "\t",index_col=0)
	frame2 = pd.read_csv(file2, delimiter = "\t",index_col=0)
	frame1seq = add_seq_to_frame(frame1)
	if bs == True:
		comparison_frame = pd.DataFrame(index = frame1seq.index,columns = [name1+' TPH BS',name1+' pvalue',name2+' TPH BS',name2+' pvalue','Sequence','Log2FC','Left Common Name','Right Common Name'])
		comparison_frame[name1+' TPH BS'] = frame1seq['TPH BS']
		comparison_frame[name2+' TPH BS'] = frame2['TPH BS']
	else:
		comparison_frame = pd.DataFrame(index = frame1seq.index,columns = [name1+' TPH',name1+' pvalue',name2+' TPH',name2+' pvalue','Sequence','Log2FC','Left Common Name','Right Common Name'])
		comparison_frame[name1+' TPH'] = frame1seq['TPH']
		comparison_frame[name2+' TPH'] = frame2['TPH']
	comparison_frame['Sequence'] = frame1seq['Sequence']
	comparison_frame['Left Common Name'] = frame1seq['Left Common Name']
	comparison_frame['Right Common Name'] = frame1seq['Right Common Name']
	if poisson:
		comparison_frame[name1+' pvalue'] = frame1seq['Poisson pvalue']
		comparison_frame[name2+' pvalue'] = frame2['Poisson pvalue']
	else:
		comparison_frame[name1+' pvalue'] = frame1seq['CHG pvalue']
		comparison_frame[name2+' pvalue'] = frame2['CHG pvalue']
	if bs == True:
		temp1 = frame1seq['TPH BS']
		temp2 = frame2['TPH BS']
	else:
		temp1 = frame1seq['TPH']
		temp2 = frame2['TPH']
	#set TPH values of zero to 1 so I can take the log
	temp1.loc[temp1 == 0] = 1
	temp2.loc[temp2 == 0] = 1
	comparison_frame['Log2FC'] = np.log2(temp2/temp1)
	return comparison_frame

#making an empty list
#df['empty_list'] = np.empty((len(df), 0)).tolist()

def add_pwm_info(inframe,tfname,cutoff,remove_overlaps=True):
	#This function takes a significant hits frame with sequence information add 
	#adds annotation about the presence of binding sites for a tf
	#it adds 3 columns.  One with a list of coordinates for each hit
	#one with the scores, and one with the orientations

	hit_starts_megalist = []
	hit_score_megalist = []
	hit_orientation_megalist = []
	#get the pssm
	tf_pssm = get_pssm(tfname)

	for idx,row in inframe.iterrows():
		hit_starts_list = []
		hit_coords_list = []
		hit_orientation_list = []
		hit_score_list = []
		#loop through all hits in a sequence
		for startpos,endpos,score,orientation in tf_pssm.search(row['Sequence'],cutoff): #test to remove warning
			#loop through all previous hits and check for overlap
			if remove_overlaps:
				overlap_flag = 0
				for ind2,val in enumerate(hit_coords_list):
					if range(max(min(startpos,endpos),min(val[0],val[1])),min(max(startpos,endpos),max(val[0],val[1]))+1):
						#replace if overlap and a better hit
						if score > hit_score_list[ind2]:
							hit_starts_list[ind2] = startpos
							hit_coords_list[ind2] = [startpos,endpos]
							hit_orientation_list[ind2] = orientation
							hit_score_list[ind2] = score
							overlap_flag = 1
						#do nothing if not a better hit
						else:
							overlap_flag = 1
				#if no overlap add to list of hits
				if not overlap_flag:
					hit_starts_list.append(startpos)
					hit_coords_list.append([startpos,endpos])
					hit_orientation_list.append(orientation)
					hit_score_list.append(score)

		#put hits in megalist
		hit_starts_megalist.append(hit_starts_list)
		hit_score_megalist.append(hit_score_list)
		hit_orientation_megalist.append(hit_orientation_list)

	inframe[tfname+' pos'] = hit_starts_megalist
	inframe[tfname+' score'] = hit_score_megalist
	inframe[tfname+' orientaion'] = hit_orientation_megalist

	return inframe		

"""
def plot_TPH_v_sites(sites_list,mean_data,std_data,dbd_mean_data,dbd_std_data):
	#This program plots TPH versus the number of TF binding sites
	#See Cbf1/Tye7 lab notebook, section Distance between sites versus binding score
	handles = []

	handles.append( plt.errorbar(sites_list,mean_data,yerr = std_data,fmt = '-o',ms=12,markerfacecolor='b',markeredgecolor='b',color='b'))

	handles.append( plt.errorbar(sites_list,dbd_mean_data,yerr = dbd_std_data,fmt = '-o',ms=12,markerfacecolor='r',markeredgecolor='r',color='r'))

	legend = ['Cbf1 FL','Cbf1 DBD']

	plt.legend(handles, legend,loc=2,numpoints = 1,fontsize=10)
	plt.axis([-1,4,-50,1700])
	plt.xlabel('Number of Sites')
	plt.ylabel('In vivo binding score (TPH)')
	plt.show()"""


def get_tpr_fpr_lists(positives,negatives,scoring_function,lowerbetter = False):
	flist = [positives, negatives]
	total = pd.concat(flist)
	total["Score"] = total["Sequence"].apply(scoring_function)
	total = total.sort_values(by=['Score'],ascending = lowerbetter)
	foundpositives = 0
	foundnegatives = 0
	num_positives = len(positives)
	num_negatives = len(negatives)
	tpr_list = []
	fpr_list = []
	for idx,row in total.iterrows():
		if idx in positives.index:
			foundpositives += 1.0
		else:
			foundnegatives += 1.0
		tpr_list.append(foundpositives/float(num_positives))
		fpr_list.append(foundnegatives/float(num_negatives))
	return tpr_list,fpr_list

def get_tpr_fpr_for_binary(positives,negatives,binary_classifier):
	"""When you iterate, stop when you get to 1,1!!"""
	flist = [positives, negatives]
	total = pd.concat(flist)
	num_positives = len(positives)
	num_negatives = len(negatives)
	foundpositives = 0
	foundnegatives = 0
	total["Classification"] = total["Sequence"].apply(binary_classifier)
	for idx,row in total.iterrows():
		if total.ix[idx]["Classification"]:	
			if idx in positives.index:
				foundpositives += 1.0
			else:
				foundnegatives += 1.0
	tpr = foundpositives/float(num_positives)
	fpr = foundnegatives/float(num_negatives)
	return tpr,fpr
"""
scan = np.arange(1,0.7,-0.1)

tpr_list = []

fpr_list = []

for val in scan:
	tpr,fpr =  get_tpr_fpr_for_binary(positives,negatives,lambda x: one_weak_one_strong(x,'cbf1',val)
 	if (tpr == 1) & (fpr == 1):
 		break
 	else:
 		tpr_list.append(tpr)
 		fpr_list.append(fpr)


 or
 tpr,fpr =  get_tpr_fpr_for_binary(positives,negatives,lambda x: one_strong_or_two_weak(x,'cbf1',val))
   """
def one_weak_one_strong(sequence,tf,cutoff,dif=3):
	tf_pssm = get_pssm(tf)
	"""cutoff = (fraction*(tf_pssm.max() - tf_pssm.min())) + tf_pssm.min()
	if (cutoff - dif) < tf_pssm.min():
		weak_cutoff = tf_pssm.min
	else:"""
	weak_cutoff = cutoff - dif
	strong = [x for x in tf_pssm.search(sequence,cutoff)]
	weak = [x for x in tf_pssm.search(sequence,weak_cutoff)]
	
	if (strong):
		if (set(weak).difference(strong)):
			return 1
		else:
			return 0
	else:
		return 0

def one_strong_or_two_weak(sequence,tf,cutoff,dif=2,dist_cutoff = 300):
	tf_pssm = get_pssm(tf)
	"""cutoff = (fraction*(tf_pssm.max() - tf_pssm.min())) + tf_pssm.min()
	if (cutoff - dif) < tf_pssm.min():
		weak_cutoff = tf_pssm.min
	else:
		weak_cutoff = cutoff - dif"""
	weak_cutoff=cutoff - dif

	#is there a strong site, if so return one:

	strong = [x for x in tf_pssm.search(sequence,cutoff)]
	if (strong):
		return 1
	else:  #check for two weak sites
		#I have to check for overlaps and also make sure the weak sites are within dist_cutoff bp
		hit_starts_list = []
		hit_coords_list = []
		hit_orientation_list = []
		hit_score_list = []
		#loop through all hits in a sequence
		for pos,hit in tf_pssm.search(sequence,weak_cutoff):
			score = hit
			if pos < 0:
				startpos = len(sequence)+pos
				endpos = len(sequence)+pos+tf_pssm.length
				orientation = 1
			else:
				startpos = pos
				endpos = pos+tf_pssm.length
				orientation = -1
			#loop through all previous hits and check for overlap
			overlap_flag = 0
			for ind2,val in enumerate(hit_coords_list):
				if range(max(startpos,val[0]),min(endpos,val[1])+1):
					#replace if overlap and a better hit
					if score > hit_score_list[ind2]:
						hit_starts_list[ind2] = startpos
						hit_coords_list[ind2] = [startpos,endpos]
						hit_orientation_list[ind2] = orientation
						hit_score_list[ind2] = score
						overlap_flag = 1
					#do nothing if not a better hit
					else:
						overlap_flag = 1
			#if no overlap add to list of hits
			if not overlap_flag:
				hit_starts_list.append(startpos)
				hit_coords_list.append([startpos,endpos])
				hit_orientation_list.append(orientation)
				hit_score_list.append(score)

		#get distances for all sites
		difflist = [abs(i-j) for i in hit_starts_list for j in hit_starts_list if i != j]
		if difflist:
			min_dist = min(difflist)
			if min_dist < dist_cutoff:
				return 1
			else:
				return 0
		else:
			return 0

def get_max_pwm_score(sequence,tf):  #i changed the order, so flip the lambda.
	tf_pssm = get_pssm(tf)
	vector = [x[2] for x in tf_pssm.search(sequence,tf_pssm.min())]
	if vector:
		y = max(vector)
	else:
		y = tf_pssm.min()
	return y

def add_cbf1_score(cf):
	cbf1_cutoff = 5
	cf = add_pwm_info(cf,'cbf1',cbf1_cutoff)
	score_list = []
	max_pos_list = []
	for idx,row in cf.iterrows():
		maxscore = 0
		maxpos = 0
		for j,score in enumerate(row["cbf1 score"]):
			if score > maxscore:
				maxscore = score
				maxpos = row["cbf1 pos"][j]
		score_list.append(maxscore)
		max_pos_list.append(maxpos)
	cf["Cbf1 Max Score"] = score_list
	cf["Cbf1 Max Pos"] = max_pos_list
	return cf


def add_tye7_collective_score(cf):
	tye7_cutoff = 5
	gcr1_cutoff = 5
	rap1_cutoff = 5
	window_size = 200
	cf = add_pwm_info(cf,'tye7',tye7_cutoff)
	cf = add_pwm_info(cf,'gcr1',gcr1_cutoff)
	cf = add_pwm_info(cf,'rap1',gcr1_cutoff)
	score_list = []
	window_start_list = []
	#loop through sequences

	for idx,row in cf.iterrows():
		best_scoring_window_idx = -1
		best_scoring_window_score = 0
		if row["tye7 pos"] or row["gcr1 pos"] or row["gcr1 pos"]:
			if row["tye7 pos"]:
				maxtye7pos = max(row["tye7 pos"])
			else:
				maxtye7pos = 1
			if row["gcr1 pos"]:
				maxgcr1pos = max(row["gcr1 pos"])
			else:
				maxgcr1pos = 1
			if row["rap1 pos"]:
				maxrap1pos = max(row["rap1 pos"])
			else:
				maxrap1pos = 1
			window_end = max(maxtye7pos,maxgcr1pos,maxrap1pos)
			for window_start in range(1,window_end-190):
				score = 0
				for j,startpos in enumerate(row["tye7 pos"]):
					if (startpos <= window_start+200) and (startpos >= window_start):
						score = score + row["tye7 score"][j]
				for j,startpos in enumerate(row["gcr1 pos"]):
					if (startpos <= window_start+200) and (startpos >= window_start):
						score = score + row["gcr1 score"][j]
				for j,startpos in enumerate(row["rap1 pos"]):
					if (startpos <= window_start+200) and (startpos >= window_start):
						score = score + row["rap1 score"][j]
				if score > best_scoring_window_score:
					best_scoring_window_idx = window_start
					best_scoring_window_score = score
		score_list.append(best_scoring_window_score)
		window_start_list.append(best_scoring_window_idx)
	cf["collective window start"] = window_start_list
	cf["Tye7 Collective Score"] = score_list
	return cf

def make_tye7_auc(cf,pcutoff,ncutoff,tph_bs_co):
	positives = cf[cf['Tye7p pvalue']<pcutoff]
	positives = positives[positives['Tye7p TPH BS']>tph_bs_co]
	negatives = cf[cf['Tye7p pvalue']>ncutoff]
	tpr,fpr = get_tpr_fpr_for_tye7(positives,negatives)
	auc = metrics.auc(fpr,tpr)
	plotROCCurve(tpr,fpr,'r','AUC ='+str(auc))

def get_tpr_fpr_for_tye7(positives,negatives):
	flist = [positives, negatives]
	total = pd.concat(flist)
	total = total.sort_values(by=['Score'],ascending = False)
	foundpositives = 0
	foundnegatives = 0
	num_positives = len(positives)
	num_negatives = len(negatives)
	tpr_list = []
	fpr_list = []
	for idx,row in total.iterrows():
		if idx in positives.index:
			foundpositives += 1.0
		else:
			foundnegatives += 1.0
		tpr_list.append(foundpositives/float(num_positives))
		fpr_list.append(foundnegatives/float(num_negatives))
	return tpr_list,fpr_list



def add_tye7_collective_score_max(cf):
	tye7_cutoff = 5
	gcr1_cutoff = 5
	rap1_cutoff = 5
	window_size = 200
	cf = add_pwm_info(cf,'tye7',tye7_cutoff)
	cf = add_pwm_info(cf,'gcr1',gcr1_cutoff)
	cf = add_pwm_info(cf,'rap1',gcr1_cutoff)
	score_list = []
	window_start_list = []
	#loop through sequences

	for idx,row in cf.iterrows():
		best_scoring_window_idx = -1
		best_scoring_window_score = 0
		if row["tye7 pos"] or row["gcr1 pos"] or row["gcr1 pos"]:
			if row["tye7 pos"]:
				maxtye7pos = max(row["tye7 pos"])
			else:
				maxtye7pos = 1
			if row["gcr1 pos"]:
				maxgcr1pos = max(row["gcr1 pos"])
			else:
				maxgcr1pos = 1
			if row["rap1 pos"]:
				maxrap1pos = max(row["rap1 pos"])
			else:
				maxrap1pos = 1
			window_end = max(maxtye7pos,maxgcr1pos,maxrap1pos)
			for window_start in range(1,window_end-190):
				score = 0

				tye7_max_score = 0
				for j,startpos in enumerate(row["tye7 pos"]):
					if (startpos <= window_start+200) and (startpos >= window_start):
						tye7_max_score = max(tye7_max_score,row["tye7 score"][j])
				score = score + tye7_max_score

				gcr1_max_score = 0
				for j,startpos in enumerate(row["gcr1 pos"]):
					if (startpos <= window_start+200) and (startpos >= window_start):
						gcr1_max_score = max(gcr1_max_score,row["gcr1 score"][j])
				score = score + gcr1_max_score
				
				rap1_max_score = 0
				for j,startpos in enumerate(row["rap1 pos"]):
					if (startpos <= window_start+200) and (startpos >= window_start):
						rap1_max_score = max(rap1_max_score,row["rap1 score"][j])
				score = score + rap1_max_score

				if score > best_scoring_window_score:
					best_scoring_window_idx = window_start
					best_scoring_window_score = score
		score_list.append(best_scoring_window_score)
		window_start_list.append(best_scoring_window_idx)
	cf["collective window start"] = window_start_list
	cf["Score"] = score_list
	return cf

	#make a window from 1 to last motif position - window size
	#compute score of overlapping motifs

def plotROCCurve(tpr,fpr, color = 'r',label = 'ROC',randomline=True):

    plt.figure(figsize=(6, 6), dpi=100)
    plt.xlabel("FPR", fontsize=16)
    plt.ylabel("TPR", fontsize=16)
    plt.title("ROC Curve", fontsize=16)
    plt.plot(fpr, tpr, color=color, linewidth=2, label=label)

    if randomline:
        x = [0.0, 1.0]
        plt.plot(x, x, linestyle='dashed', color='red', linewidth=2, label='random')

    plt.xlim(0.0, 1.0)
    plt.ylim(0.0, 1.0)
    plt.tick_params(axis='both', which='major', labelsize=16)
	#plt.tick_params(axis='both', which='minor', labelsize=8)
    plt.legend(fontsize=14, loc='best')
    plt.tight_layout()
    plt.show()

def coilplot(cf,name1='FL',name2='DBD',tfname='cbf1',cutoff=9):
	 cf = add_pwm_info(cf,tfname,cutoff)
	 cf["Num Sites"] = cf[tfname+' pos'].apply(len)
	 grouped = cf.groupby(['Num Sites'])
	 mean_data = grouped.aggregate(np.mean)[name1+' TPH'][0:4]
	 std_data = grouped.aggregate(np.std)[name1+' TPH'][0:4]
	 fig = plt.figure(figsize = (8,6))
	 ax1 = fig.add_subplot(111)
	 handles = []
	 handles.append(ax1.errorbar(list(mean_data.index),list(mean_data),yerr = list(std_data),fmt = '-o',ms=12,
	 	markerfacecolor='b',markeredgecolor='b',linewidth=1))
	 mean_data = grouped.aggregate(np.mean)[name2+' TPH'][0:4]
	 std_data = grouped.aggregate(np.std)[name2+' TPH'][0:4]
	 handles.append(ax1.errorbar(list(mean_data.index),list(mean_data),yerr = list(std_data),fmt = '-o',ms=12,
	 	markerfacecolor='r',markeredgecolor='r',linewidth=1,color='r'))
	 legend = ['Cbf1 FL','Cbf1 DBD no coil']
	 ax1.legend(handles, legend,loc=2,numpoints = 1,fontsize=14)
	 ax1.set_ylim([0,2000])
	 ax1.set_xlim([-1,4])
	 ax1.set_ylabel('Cbf1 in vivo binding score (TPH)')
	 ax1.set_xlabel('Number of Sites')
	 for item in ([ax1.xaxis.label, ax1.yaxis.label] + ax1.get_xticklabels() + ax1.get_yticklabels()):
		item.set_fontsize(16)
	 plt.show()

def output_matlab_text(sig_frame,cutoff,epsilon_col_name,hops_filename="hops.txt",epsilon_filename="epsilon.txt"):
	sig_frame = sig_frame.sort_values(["TPH BS"],ascending = False)
	hops_output = sig_frame[sig_frame["TPH BS"]>cutoff]["TPH BS"]
	hops_output.to_csv(hops_filename,index=None,header=None)
	epsilon_output = sig_frame[sig_frame["TPH BS"]>cutoff][epsilon_col_name].copy()
	max_len = max(epsilon_output.apply(len))
	out_list = list([])
	for row in epsilon_output:
		temp = [-x for x in row]
		out_list = out_list + [(temp+[999]*(max_len-len(row)))]
	df = pd.DataFrame(out_list)
	df.to_csv(epsilon_filename,sep="\t",header=None,index=None)





